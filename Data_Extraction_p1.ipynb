{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nml7ZrBloi7P",
        "outputId": "0320f5d3-7ec9-4b97-8234-a095b6e7a7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install pandas openpyxl\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Step 2: Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install striprtf pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otzmYKrNITpW",
        "outputId": "05d347f4-6242-4b29-c16d-0c5c856f10b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.27-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading striprtf-0.0.27-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "crbnHYFFIeeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "from docx import Document"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPsuwtu1KhDv",
        "outputId": "9394d0dd-5367-4b74-fe72-3ccb37ba5b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file_path = '/content/drive/MyDrive/collab_code/Text_data/p_2552.docx'\n",
        "output_folder_path = '/content/drive/MyDrive/collab_code/Organized_Data'\n",
        "output_file_name = 'p_2552.xlsx'\n",
        "output_file_path = os.path.join(output_folder_path, output_file_name)\n",
        "\n",
        "# Step 4: Read the data from the DOCX file using python-docx\n",
        "\n",
        "\n",
        "# Open the DOCX file and read the data\n",
        "doc = Document(input_file_path)\n",
        "data = [para.text for para in doc.paragraphs if para.text.strip()]  # Filter out empty lines\n",
        "\n",
        "# Step 5: Process and clean the data to store thread, message, date, and likes\n",
        "organized_data = []\n",
        "current_thread = None\n",
        "current_message = None\n",
        "current_date = None\n",
        "current_likes = None\n",
        "\n",
        "# Iterate over all lines and capture threads, messages, dates, and likes\n",
        "for line in data:\n",
        "    if line.startswith('Thread:'):  # If the line starts with 'Thread:', it's a new thread\n",
        "        current_thread = line.strip().replace('Thread: ', '')\n",
        "    elif line.startswith('Message:'):  # If the line starts with 'Message:', it's a new message\n",
        "        current_message = line.strip().split(': ', 1)[1]\n",
        "    elif line.startswith('Date:'):  # If the line starts with 'Date:', it's the message date\n",
        "        current_date = line.strip().split('Date: ')[1]  # Capture the date\n",
        "    elif line.startswith('Likes:'):  # If the line starts with 'Likes:', it's the message likes\n",
        "        current_likes = line.strip().split('Likes: ')[1]  # Capture the likes\n",
        "        # Append the data (Thread, Message, Date, Likes) to the organized data\n",
        "        organized_data.append([current_thread, current_message, current_date, current_likes])\n",
        "\n",
        "# Step 6: Convert the parsed data to a pandas DataFrame\n",
        "df = pd.DataFrame(organized_data, columns=['Thread', 'Message', 'Date', 'Likes'])\n",
        "\n",
        "# Step 7: Save the DataFrame to an Excel file\n",
        "df.to_excel(output_file_path, index=False)\n",
        "\n",
        "# Step 8: Confirmation\n",
        "print(f\"Data successfully saved to: {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhY_UJHTF50e",
        "outputId": "7cccfa86-43b4-4e92-9396-132d80ea39fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully saved to: /content/drive/MyDrive/collab_code/Organized_Data/p_2552.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "opjnJkBXDPqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/collab_code/Organized_Data'\n",
        "\n",
        "# Step 3: Use glob to find all Excel files in the folder\n",
        "file_paths = glob.glob(folder_path + \"*.xlsx\")\n",
        "\n",
        "# Step 4: Merge all Excel files into a single DataFrame\n",
        "all_data = pd.concat([pd.read_excel(file) for file in file_paths], ignore_index=True)\n",
        "\n",
        "# Step 5: Save the combined data to a new Excel file\n",
        "output_path = '/content/drive/MyDrive/collab_code/merge/merged_output_final.xlsx'\n",
        "all_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"All files merged and saved to {output_path}\")"
      ],
      "metadata": {
        "id": "piQWZZmuG2PI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "158666fa-5317-4a94-bd2a-0cc91218be5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No objects to concatenate",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7547971f65d1>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Step 4: Merge all Excel files into a single DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 5: Save the combined data to a new Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_keys_and_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = glob.glob(folder_path + \"*.xlsx\")\n"
      ],
      "metadata": {
        "id": "BnOSnu4E1Fkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = glob.glob(folder_path + \"/*.xlsx\")\n"
      ],
      "metadata": {
        "id": "fBpbpiqQ1NA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/collab_code/Organized_Data'\n",
        "\n",
        "# Step 3: Use glob to find all Excel files in the folder\n",
        "file_paths = glob.glob(folder_path + \"/*.xlsx\")\n",
        "\n",
        "# Check if any files were found\n",
        "if not file_paths:\n",
        "    print(\"No Excel files found in the specified folder.\")\n",
        "else:\n",
        "    print(f\"Found {len(file_paths)} files: {file_paths}\")\n",
        "\n",
        "    # Step 4: Merge all Excel files into a single DataFrame\n",
        "    dfs = [pd.read_excel(file) for file in file_paths if not pd.read_excel(file).empty]\n",
        "\n",
        "    if not dfs:\n",
        "        print(\"No valid data found in the Excel files.\")\n",
        "    else:\n",
        "        all_data = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "        # Step 5: Save the combined data to a new Excel file\n",
        "        output_path = '/content/drive/MyDrive/collab_code/merge/merged_output_final.xlsx'\n",
        "        all_data.to_excel(output_path, index=False)\n",
        "\n",
        "        print(f\"All files merged and saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY1hZC1m1OjA",
        "outputId": "93d032c0-b128-4930-dfea-74267cfe8d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 262 files: ['/content/drive/MyDrive/collab_code/Organized_Data/p_2126.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_20.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1337.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_3.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_6.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_7.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_9.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_10.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_12.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_13.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_11.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_4.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_16.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_17.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_18.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_19.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_24.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_25.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_26.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_28.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_31.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_32.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_33.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_34.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_37.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_40.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_42.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_43.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_46.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_47.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_48.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_49.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_50.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_51.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_52.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_54.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_56.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_57.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_58.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_59.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_60.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_62.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_63.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_66.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_68.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_69.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_70.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_72.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_73.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_76.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_79.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_504.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_508.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_512.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_513.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_514.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_518.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_519.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_521.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_523.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_525.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_526.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_527.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_529.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_530.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_533.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_535.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_537.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_538.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_540.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_541.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_544.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_555.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_557.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_559.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_561.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_567.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_45.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_71.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_568.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_569.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_571.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_572.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_573.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_578.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_580.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_587.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_588.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_591.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_594.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_595.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_596.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_597.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_599.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_601.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_902.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_904.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_906.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_908.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_912.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_913.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_915.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_917.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_918.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_920.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_921.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_922.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_925.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_927.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_928.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_930.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_931.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_932.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_933.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_934.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_937.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_938.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_941.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_942.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_944.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_945.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_946.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_947.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_948.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_949.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_950.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_951.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_954.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_958.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_959.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_960.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_589.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_980.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_962.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_963.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_964.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_966.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_967.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_968.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_969.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_970.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_971.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_972.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_974.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_975.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_976.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_977.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_981.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1201.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1203.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1205.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1206.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1207.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1208.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1209.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1213.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1217.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1222.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1224.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1226.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1227.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1228.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1262.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1257.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1254.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1251.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1244.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1243.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1242.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1241.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1240.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1238.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1236.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1235.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1232.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1230.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1229.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1264.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1266.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1267.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1269.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1271.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1273.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1274.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1276.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1277.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1279.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1280.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1282.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1283.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1284.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1286.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1288.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1289.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1291.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1295.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1296.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1298.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1301.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1302.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1303.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1304.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1306.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1309.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1312.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1317.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1319.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1320.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1322.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1323.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1324.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1325.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1327.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1329.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1330.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1331.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1332.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1335.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1338.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1339.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1345.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1349.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1351.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1352.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1501.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1506.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1509.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1511.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1513.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1515.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1516.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1517.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1519.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1904.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1905.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_1907.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2107.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2116.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2123.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2124.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2127.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2130.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2132.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2138.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2139.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2141.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2146.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2147.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2149.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2150.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2159.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2161.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2162.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2166.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2510.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2519.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2520.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2522.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2523.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2532.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2534.xlsx', '/content/drive/MyDrive/collab_code/Organized_Data/p_2552.xlsx']\n",
            "All files merged and saved to /content/drive/MyDrive/collab_code/merge/merged_output_final.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAwXTV9Q1OUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-xW3IT01Nyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/drive/MyDrive/collab_code/Organized_Data'\n",
        "\n",
        "# Step 3: Use glob to find all Excel files in the folder\n",
        "file_paths = glob.glob(folder_path + \"*.xlsx\")\n",
        "\n",
        "# Check if any files are found in the folder\n",
        "file_paths = glob.glob(folder_path + \"*.xlsx\")\n",
        "print(\"Files found:\", file_paths)  # Print the list of files found\n",
        "\n",
        "# If no files are found, try updating the folder path or checking file extensions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEU6AHgBDks5",
        "outputId": "6dcc5556-07e9-4762-bfbb-d3bea06c5a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files found: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "lqokhhZ0Ed8g",
        "outputId": "bfc13013-2d79-4e40-e153-140b650b3b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58159b1e-584d-419c-aa3f-148754923d0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58159b1e-584d-419c-aa3f-148754923d0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving p_3.xlsx to p_3 (2).xlsx\n",
            "Saving p_4.xlsx to p_4 (1).xlsx\n",
            "Saving p_6.xlsx to p_6 (1).xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming the uploaded file is named 'your_file.xlsx'\n",
        "df = pd.read_excel('p_3 (2).xlsx')\n",
        "df1 = pd.read_excel('p_4 (1).xlsx')\n",
        "df2 = pd.read_excel('p_6 (1).xlsx')\n",
        "print(df.head())  # Display the first few rows of the file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iudnAq8Z2Op2",
        "outputId": "dc0da1dc-4917-49f6-a244-8ba69ab8aab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Thread                                            Message  \\\n",
            "0       1  [0] congratulations to my brother Michael Pelf...   \n",
            "1       1                      [1] Nah, Roll Tide regardless   \n",
            "2       1  [2] I'm not saying God has a preference, but A...   \n",
            "3       1                 [0] too soon for jokes phil hahaha   \n",
            "4       2            [3] Your photos are adorable! Miss you!   \n",
            "\n",
            "                              Date                    Likes  \n",
            "0  Mon, 30 May 2011 14:13:09 -0700  5 (5 people like this.)  \n",
            "1  Mon, 30 May 2011 15:29:24 -0700                        1  \n",
            "2  Mon, 30 May 2011 16:09:22 -0700                        1  \n",
            "3  Mon, 30 May 2011 16:54:39 -0700                        0  \n",
            "4  Mon, 30 May 2011 13:43:50 -0700                        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IrB0PSso2XuE",
        "outputId": "0e19bd6c-8f7b-442f-fe86-c5ef7e3838ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Thread                                            Message  \\\n",
              "0       1  [0] congratulations to my brother Michael Pelf...   \n",
              "1       1                      [1] Nah, Roll Tide regardless   \n",
              "2       1  [2] I'm not saying God has a preference, but A...   \n",
              "3       1                 [0] too soon for jokes phil hahaha   \n",
              "4       2            [3] Your photos are adorable! Miss you!   \n",
              "\n",
              "                              Date                    Likes  \n",
              "0  Mon, 30 May 2011 14:13:09 -0700  5 (5 people like this.)  \n",
              "1  Mon, 30 May 2011 15:29:24 -0700                        1  \n",
              "2  Mon, 30 May 2011 16:09:22 -0700                        1  \n",
              "3  Mon, 30 May 2011 16:54:39 -0700                        0  \n",
              "4  Mon, 30 May 2011 13:43:50 -0700                        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5847919b-9c65-4505-9e05-e47dc33c670c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Thread</th>\n",
              "      <th>Message</th>\n",
              "      <th>Date</th>\n",
              "      <th>Likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0] congratulations to my brother Michael Pelf...</td>\n",
              "      <td>Mon, 30 May 2011 14:13:09 -0700</td>\n",
              "      <td>5 (5 people like this.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1] Nah, Roll Tide regardless</td>\n",
              "      <td>Mon, 30 May 2011 15:29:24 -0700</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[2] I'm not saying God has a preference, but A...</td>\n",
              "      <td>Mon, 30 May 2011 16:09:22 -0700</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[0] too soon for jokes phil hahaha</td>\n",
              "      <td>Mon, 30 May 2011 16:54:39 -0700</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>[3] Your photos are adorable! Miss you!</td>\n",
              "      <td>Mon, 30 May 2011 13:43:50 -0700</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5847919b-9c65-4505-9e05-e47dc33c670c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5847919b-9c65-4505-9e05-e47dc33c670c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5847919b-9c65-4505-9e05-e47dc33c670c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-709ed596-d991-40fc-be13-3dba7ce74858\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-709ed596-d991-40fc-be13-3dba7ce74858')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-709ed596-d991-40fc-be13-3dba7ce74858 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 135,\n  \"fields\": [\n    {\n      \"column\": \"Thread\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          62,\n          58,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 126,\n        \"samples\": [\n          \"[0] ya i remember that... this was way too similar. and honestly the extent of the damage from what i heard is a lot worse here\",\n          \"[0] already been there twice :/ haha. opps. but im sure ill come up again before they get out of school. we should meet up at the outlets one day too!\",\n          \"[0] whos staying in tuscaloosa this weekend :)????\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 135,\n        \"samples\": [\n          \"Wed, 27 Apr 2011 18:57:30 -0700\",\n          \"Thu, 28 Apr 2011 09:00:45 -0700\",\n          \"Wed, 27 Apr 2011 16:23:21 -0700\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Likes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"1 (Kari Hellman likes this.)\",\n          \"1 (Katie Middleton likes this.)\",\n          \"5 (5 people like this.)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "hPnxMrK-7DDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have two DataFrames, df and df1\n",
        "data = pd.concat([df, df1], ignore_index=True)\n",
        "data1 = pd.concat([data, df2], ignore_index=True)\n",
        "\n",
        "# Display the concatenated DataFrame\n",
        "print(data1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyIX8yAR7fGy",
        "outputId": "ba67834e-7294-4cbf-e1a7-ecd2ad24ca7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Thread                                            Message  \\\n",
            "0         1  [0] congratulations to my brother Michael Pelf...   \n",
            "1         1                      [1] Nah, Roll Tide regardless   \n",
            "2         1  [2] I'm not saying God has a preference, but A...   \n",
            "3         1                 [0] too soon for jokes phil hahaha   \n",
            "4         2            [3] Your photos are adorable! Miss you!   \n",
            "..      ...                                                ...   \n",
            "406     115  [27] oh meghan. i wanna hear all about your ni...   \n",
            "407     116  [20] Dear Meghan, I just wanted you to be the ...   \n",
            "408     117  [3] We're scared of almost everything, afraid ...   \n",
            "409     118                      [24] happy anniversary baby ♥   \n",
            "410     118                                      [3] xoxoxoxxx   \n",
            "\n",
            "                                Date                    Likes  \n",
            "0    Mon, 30 May 2011 14:13:09 -0700  5 (5 people like this.)  \n",
            "1    Mon, 30 May 2011 15:29:24 -0700                        1  \n",
            "2    Mon, 30 May 2011 16:09:22 -0700                        1  \n",
            "3    Mon, 30 May 2011 16:54:39 -0700                        0  \n",
            "4    Mon, 30 May 2011 13:43:50 -0700                        0  \n",
            "..                               ...                      ...  \n",
            "406  Thu, 21 Apr 2011 05:29:45 -0700                        1  \n",
            "407  Wed, 20 Apr 2011 18:59:33 -0700                        0  \n",
            "408  Wed, 20 Apr 2011 17:14:01 -0700  2 (2 people like this.)  \n",
            "409  Wed, 20 Apr 2011 05:52:06 -0700                        0  \n",
            "410  Wed, 20 Apr 2011 09:35:00 -0700                        0  \n",
            "\n",
            "[411 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eeOVzG5m7yQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Define the file path\n",
        "file_path = '/content/drive/MyDrive/collab_code/merge/merged_output_final.xlsx'\n",
        "\n",
        "# Step 2: Read the Excel file\n",
        "data = pd.read_excel(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "O_TFtFG-5Byl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Remove rows where the 'Message' column is empty or contains only whitespace\n",
        "cleaned_data = data[data['Message'].str.strip().astype(bool)]\n",
        "\n",
        "# Step 4: Remove rows where the 'Message' only contains patterns like \"[1]\", \"[2]\", etc.\n",
        "pattern = r\"^\\[\\d+\\]$\"\n",
        "final_cleaned_data = cleaned_data[~cleaned_data['Message'].str.strip().str.match(pattern)]\n",
        "\n",
        "# Step 5: Save the cleaned data to a new Excel file\n",
        "output_path = '/content/drive/MyDrive/collab_code/merge/cleaned_output_final2.xlsx'\n",
        "final_cleaned_data.to_excel(output_path, index=False)\n",
        "\n",
        "print(f\"Cleaned data has been saved to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxu_jTJe5EiK",
        "outputId": "d09b0cbd-a6bb-4877-c5da-34b6d852d423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned data has been saved to /content/drive/MyDrive/collab_code/merge/cleaned_output_final2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'Date' column to a datetime format\n",
        "final_cleaned_data['Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce')\n",
        "\n",
        "# Define the date ranges\n",
        "start_date = pd.Timestamp(\"2009-09-01\")\n",
        "split_1_end = pd.Timestamp(\"2011-04-27 15:00\")\n",
        "split_2_start = pd.Timestamp(\"2011-04-27 15:01\")\n",
        "split_2_end = pd.Timestamp(\"2011-04-30 15:00\")\n",
        "\n",
        "# Split the dataset into three parts based on the date ranges\n",
        "dataset_1 = final_cleaned_data[(final_cleaned_data['Date'] >= start_date) & (final_cleaned_data['Date'] <= split_1_end)]\n",
        "dataset_2 = final_cleaned_data[(final_cleaned_data['Date'] > split_2_start) & (final_cleaned_data['Date'] <= split_2_end)]\n",
        "dataset_3 = final_cleaned_data[final_cleaned_data['Date'] > split_2_end]\n",
        "\n",
        "# Display the datasets to the user\n",
        "import ace_tools as tools\n",
        "tools.display_dataframe_to_user(name=\"Dataset 1\", dataframe=dataset_1)\n",
        "tools.display_dataframe_to_user(name=\"Dataset 2\", dataframe=dataset_2)\n",
        "tools.display_dataframe_to_user(name=\"Dataset 3\", dataframe=dataset_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "DQjGn-qw5Nr2",
        "outputId": "9a40f5b7-7914-4c1b-9fee-dc7d0b7b010c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-4ce26e928446>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  final_cleaned_data['Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid comparison between dtype=datetime64[ns, UTC-07:00] and Timestamp",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m_validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIncompatibleFrequency\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_check_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_tzawareness_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36m_assert_tzawareness_compat\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mother_tz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0;34m\"Cannot compare tz-naive and tz-aware datetime-like objects\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot compare tz-naive and tz-aware datetime-like objects",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInvalidComparison\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_comparison_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m_validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    538\u001b[0m                 \u001b[0;31m# e.g. tzawareness mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidComparison\u001b[0m: 2009-09-01 00:00:00",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4ce26e928446>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Split the dataset into three parts based on the date ranges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplit_1_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdataset_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_2_start\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplit_2_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdataset_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_2_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ge__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6117\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6119\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    328\u001b[0m     ):\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Call the method on lvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: but not pd.NA?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ge__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__ge__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# -------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimelike.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_comparison_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidComparison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minvalid_comparison\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/ops/invalid.py\u001b[0m in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid comparison between dtype={left.dtype} and {typ}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=datetime64[ns, UTC-07:00] and Timestamp"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Step 1: Define the file path\n",
        "file_path = '/content/drive/MyDrive/collab_code/merge/cleaned_output_final2.xlsx'\n",
        "\n",
        "\n",
        "# Step 2: Read the Excel file\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Step 3: Remove rows where the 'Message' column is empty or contains only whitespace\n",
        "cleaned_data = data[data['Message'].str.strip().astype(bool)]\n",
        "\n",
        "# Step 4: Remove rows where the 'Message' only contains patterns like \"[1]\", \"[2]\", etc.\n",
        "pattern = r\"^\\[\\d+\\]$\"\n",
        "final_cleaned_data = cleaned_data[~cleaned_data['Message'].str.strip().str.match(pattern)]\n",
        "\n",
        "# Step 5: Convert the 'Date' column to datetime format and remove timezone information\n",
        "final_cleaned_data.loc[:, 'Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce').dt.tz_convert(None)\n",
        "\n",
        "# Step 6: Define the date ranges (timezone-naive)\n",
        "start_date = pd.Timestamp(\"2009-09-01\")\n",
        "split_1_end = pd.Timestamp(\"2011-04-27 15:00\")\n",
        "split_2_start = pd.Timestamp(\"2011-04-27 15:01\")\n",
        "split_2_end = pd.Timestamp(\"2011-04-30 15:00\")\n",
        "\n",
        "# Step 7: Split the dataset into three parts based on the date ranges\n",
        "dataset_1 = final_cleaned_data[(final_cleaned_data['Date'] >= start_date) & (final_cleaned_data['Date'] <= split_1_end)]\n",
        "dataset_2 = final_cleaned_data[(final_cleaned_data['Date'] > split_2_start) & (final_cleaned_data['Date'] <= split_2_end)]\n",
        "dataset_3 = final_cleaned_data[final_cleaned_data['Date'] > split_2_end]\n",
        "\n",
        "# Step 8: Save the datasets to new Excel files\n",
        "output_path_1 = '/content/drive/MyDrive/collab_code/merge/dataset_1.xlsx'\n",
        "output_path_2 = '/content/drive/MyDrive/collab_code/merge/dataset_2.xlsx'\n",
        "output_path_3 = '/content/drive/MyDrive/collab_code/merge/dataset_3.xlsx'\n",
        "\n",
        "dataset_1.to_excel(output_path_1, index=False)\n",
        "dataset_2.to_excel(output_path_2, index=False)\n",
        "dataset_3.to_excel(output_path_3, index=False)\n",
        "\n",
        "print(f\"Dataset 1 saved to {output_path_1}\")\n",
        "print(f\"Dataset 2 saved to {output_path_2}\")\n",
        "print(f\"Dataset 3 saved to {output_path_3}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKPVxxvT7gkS",
        "outputId": "f6ca1632-f8cc-47f8-cb48-8286202bd877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 saved to /content/drive/MyDrive/collab_code/merge/dataset_1.xlsx\n",
            "Dataset 2 saved to /content/drive/MyDrive/collab_code/merge/dataset_2.xlsx\n",
            "Dataset 3 saved to /content/drive/MyDrive/collab_code/merge/dataset_3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Date'].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jerEI127xh_",
        "outputId": "2fa4ab37-f569-4147-9752-63faa3e2935d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Tue, 31 May 2011 20:22:05 -0700\n",
            "1    Wed, 01 Jun 2011 09:46:56 -0700\n",
            "2    Tue, 31 May 2011 19:17:02 -0700\n",
            "3    Tue, 31 May 2011 09:57:14 -0700\n",
            "4    Tue, 31 May 2011 10:05:52 -0700\n",
            "5    Tue, 31 May 2011 10:08:36 -0700\n",
            "6    Tue, 31 May 2011 10:11:28 -0700\n",
            "7    Tue, 31 May 2011 10:12:10 -0700\n",
            "8    Tue, 31 May 2011 16:42:49 -0700\n",
            "9    Tue, 31 May 2011 19:06:58 -0700\n",
            "Name: Date, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[final_cleaned_data['Date'].isna()].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_gwewWv80CZ",
        "outputId": "e07b8a98-f700-4dc3-981b-c4e9e33ef927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Thread                                            Message  \\\n",
            "1      2126                    [1] Myyyyyy nuhhhhwww nuuhhhwww   \n",
            "174    2126  [1] Any storm victims, outback is at snow Hint...   \n",
            "175    2126  [58] Posted this on my wall so my friend can s...   \n",
            "176    2126  [4] I'm so proud to call Ttown my home! You al...   \n",
            "177    2126  [59] Hey honey... I'm glad you're ok. I was wo...   \n",
            "\n",
            "                                Date                           Likes  \n",
            "1    Wed, 01 Jun 2011 09:46:56 -0700                               0  \n",
            "174  Sat, 30 Apr 2011 09:28:28 -0700         9 (9 people like this.)  \n",
            "175  Sat, 30 Apr 2011 09:43:43 -0700                               0  \n",
            "176  Sat, 30 Apr 2011 09:51:08 -0700                               0  \n",
            "177  Fri, 29 Apr 2011 23:29:50 -0700  1 (Chance A Blake likes this.)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_cleaned_data['Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce').dt.tz_localize(None)\n"
      ],
      "metadata": {
        "id": "07w9Au9S86AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: Remove null values in the 'Date' column\n",
        "final_cleaned_data = final_cleaned_data.dropna(subset=['Date'])\n",
        "\n",
        "# Step 6: Convert the 'Date' column to datetime format, convert to UTC, and remove the timezone\n",
        "final_cleaned_data['Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce').dt.tz_convert('UTC').dt.tz_localize(None)\n",
        "\n",
        "# Step 7: Define the date ranges (timezone-naive)\n",
        "start_date = pd.Timestamp(\"2009-09-01\")\n",
        "split_1_end = pd.Timestamp(\"2011-04-27 15:00\")\n",
        "split_2_start = pd.Timestamp(\"2011-04-27 15:01\")\n",
        "split_2_end = pd.Timestamp(\"2011-04-30 15:00\")\n",
        "\n",
        "# Step 8: Split the dataset into three parts based on the date ranges\n",
        "dataset_1 = final_cleaned_data[(final_cleaned_data['Date'] >= start_date) & (final_cleaned_data['Date'] <= split_1_end)]\n",
        "dataset_2 = final_cleaned_data[(final_cleaned_data['Date'] > split_2_start) & (final_cleaned_data['Date'] <= split_2_end)]\n",
        "dataset_3 = final_cleaned_data[final_cleaned_data['Date'] > split_2_end]\n",
        "\n",
        "# Step 9: Save the datasets to new Excel files\n",
        "output_path_1 = '/content/drive/MyDrive/collab_code/merge/dataset_1.xlsx'\n",
        "output_path_2 = '/content/drive/MyDrive/collab_code/merge/dataset_2.xlsx'\n",
        "output_path_3 = '/content/drive/MyDrive/collab_code/merge/dataset_3.xlsx'\n",
        "\n",
        "dataset_1.to_excel(output_path_1, index=False)\n",
        "dataset_2.to_excel(output_path_2, index=False)\n",
        "dataset_3.to_excel(output_path_3, index=False)\n",
        "\n",
        "print(f\"Dataset 1 saved to {output_path_1}\")\n",
        "print(f\"Dataset 2 saved to {output_path_2}\")\n",
        "print(f\"Dataset 3 saved to {output_path_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xsRQKU42_Xgl",
        "outputId": "6d769060-77cf-4c3e-b364-cef87fe6195b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot convert tz-naive timestamps, use tz_localize to localize",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-e24f07a7e207>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Step 6: Convert the 'Date' column to datetime format, convert to UTC, and remove the timezone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_cleaned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTC'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Step 7: Define the date ranges (timezone-naive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_create_delegator_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delegate_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m_delegate_method\u001b[0;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mtz_convert\u001b[0;34m(self, tz)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_references\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/arrays/datetimes.py\u001b[0m in \u001b[0;36mtz_convert\u001b[0;34m(self, tz)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;31m# tz naive, use tz_localize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    916\u001b[0m                 \u001b[0;34m\"Cannot convert tz-naive timestamps, use tz_localize to localize\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             )\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert tz-naive timestamps, use tz_localize to localize"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Remove null values in the 'Date' column\n",
        "final_cleaned_data = final_cleaned_data.dropna(subset=['Date'])\n",
        "\n",
        "# Step 6: Convert the 'Date' column to datetime format, localize naive timestamps to UTC, and then remove the timezone\n",
        "final_cleaned_data['Date'] = pd.to_datetime(final_cleaned_data['Date'], errors='coerce')\n",
        "final_cleaned_data['Date'] = final_cleaned_data['Date'].apply(lambda x: x.tz_localize('UTC') if x.tzinfo is None else x)\n",
        "final_cleaned_data['Date'] = final_cleaned_data['Date'].dt.tz_convert('UTC').dt.tz_localize(None)\n",
        "\n",
        "# Step 7: Define the date ranges (timezone-naive)\n",
        "start_date = pd.Timestamp(\"2009-09-01\")\n",
        "split_1_end = pd.Timestamp(\"2011-04-27 15:00\")\n",
        "split_2_start = pd.Timestamp(\"2011-04-27 15:01\")\n",
        "split_2_end = pd.Timestamp(\"2011-04-30 15:00\")\n",
        "\n",
        "# Step 8: Split the dataset into three parts based on the date ranges\n",
        "dataset_1 = final_cleaned_data[(final_cleaned_data['Date'] >= start_date) & (final_cleaned_data['Date'] <= split_1_end)]\n",
        "dataset_2 = final_cleaned_data[(final_cleaned_data['Date'] > split_2_start) & (final_cleaned_data['Date'] <= split_2_end)]\n",
        "dataset_3 = final_cleaned_data[final_cleaned_data['Date'] > split_2_end]\n",
        "\n",
        "# Step 9: Save the datasets to new Excel files\n",
        "output_path_1 = '/content/drive/MyDrive/collab_code/merge/dataset_1.xlsx'\n",
        "output_path_2 = '/content/drive/MyDrive/collab_code/merge/dataset_2.xlsx'\n",
        "output_path_3 = '/content/drive/MyDrive/collab_code/merge/dataset_3.xlsx'\n",
        "\n",
        "dataset_1.to_excel(output_path_1, index=False)\n",
        "dataset_2.to_excel(output_path_2, index=False)\n",
        "dataset_3.to_excel(output_path_3, index=False)\n",
        "\n",
        "print(f\"Dataset 1 saved to {output_path_1}\")\n",
        "print(f\"Dataset 2 saved to {output_path_2}\")\n",
        "print(f\"Dataset 3 saved to {output_path_3}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTfSbmSEAJyi",
        "outputId": "138ba73c-2b2f-492c-805d-7f9e475fb446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 saved to /content/drive/MyDrive/collab_code/merge/dataset_1.xlsx\n",
            "Dataset 2 saved to /content/drive/MyDrive/collab_code/merge/dataset_2.xlsx\n",
            "Dataset 3 saved to /content/drive/MyDrive/collab_code/merge/dataset_3.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpdxCkYCAdMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}